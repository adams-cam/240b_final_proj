
R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> rm(list=ls())
> 
> 
> # lod pacakges
> library(tidyverse)
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.2     ✔ purrr   0.3.4
✔ tibble  3.0.4     ✔ dplyr   1.0.2
✔ tidyr   1.1.2     ✔ stringr 1.4.0
✔ readr   1.4.0     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
> library(data.table)

Attaching package: ‘data.table’

The following objects are masked from ‘package:dplyr’:

    between, first, last

The following object is masked from ‘package:purrr’:

    transpose

> library(survival)
> library(skimr)
> library(scales)

Attaching package: ‘scales’

The following object is masked from ‘package:purrr’:

    discard

The following object is masked from ‘package:readr’:

    col_factor

> library(origami)
origami v1.0.3: Generalized Framework for Cross-Validation
> #library(future)
> library(survtmle)
survtmle: Targeted Learning for Survival Analysis
Version: 1.1.3
> options(sl3.verbose = TRUE)
> library(sl3)
> 
> # set dplyr functions b/c of server issues 
> select <- dplyr::select
> filter <- dplyr::filter
> mutate <- dplyr::mutate
> 
> # load data
> db <- load(file = paste0(#"~/Google Drive/01_semester_archive/11_Fall_2020/ph240b/", 
+   "~/repos/240b_final_proj/final_proj.RData"))
> db
[1] "cov"      "gene_exp"
> 
> dim(cov)
[1] 300   8
> cov %>% head
  Sample_type Sample_source_name Sample_organism_ch1 cancer_stage
1         RNA    cervical cancer        Homo sapiens          IB1
2         RNA    cervical cancer        Homo sapiens          IB1
3         RNA    cervical cancer        Homo sapiens          IB1
4         RNA    cervical cancer        Homo sapiens          IB1
5         RNA    cervical cancer        Homo sapiens          IB1
6         RNA    cervical cancer        Homo sapiens          IB1
  largest_diameter disease_free_survival_months status_of_dfs
1               22                          230             1
2               23                            9             1
3               13                           71             1
4               21                          281             1
5               14                          262             1
6               22                          272             1
  sample_description
1           SAMPLE 1
2           SAMPLE 2
3           SAMPLE 3
4           SAMPLE 4
5           SAMPLE 5
6           SAMPLE 6
> dim(gene_exp)
[1]   300 29378
> 
> 
> #-------------------------------------------------------------------------------
> # Set up data
> #-------------------------------------------------------------------------------
> 
> #cov <- cov %>%
> #  mutate(disease_free_survival_months = round(scales::rescale(disease_free_survival_months, c(1, 150)), 0),
> #    survival_120_months = ifelse(disease_free_survival_months > 120, 120, 
> #                                 disease_free_survival_months),
> #    status_120_months = ifelse(disease_free_survival_months < 120 & status_of_dfs == 2, 
> #                          1, 0))
> #summary(cov$disease_free_survival_months)
> #with(cov, table(status_of_dfs, status_120_months))                                 
> 
> 
> dat <- cov %>% mutate(id = paste0("ID", 1:nrow(.)), 
+                       status = as.integer(status_of_dfs-1),
+                       #ftype = status_of_dfs-1, # 1 = recurrence, 0 no reccurence
+                       ftype = status, # 1 = recurrence, 0 no reccurence
+                       time = disease_free_survival_months,
+                       #time = survival_120_months,
+                       ftime = time, 
+                       cancer_stage = as.factor(cancer_stage), 
+                       largest_diameter = as.integer(largest_diameter)) %>% 
+   select(ftype, ftime, status, cancer_stage, largest_diameter) %>%  
+   bind_cols(gene_exp)
> 
> dat %>% select(1:10) %>% head
  ftype ftime status cancer_stage largest_diameter ID_REF ILMN_1343291
1     0   230      0          IB1               22      1          195
2     0     9      0          IB1               23      2          207
3     0    71      0          IB1               13      3           80
4     0   281      0          IB1               21      4           15
5     0   262      0          IB1               14      5          125
6     0   272      0          IB1               22      6          172
  ILMN_1651209 ILMN_1651228 ILMN_1651229
1            7          149          210
2          260          146          251
3          261            5          218
4          109           47           36
5          237          135          265
6          168          138          261
> table(dat$ftype, dat$status) %>% addmargins
     
        0   1 Sum
  0   262   0 262
  1     0  38  38
  Sum 262  38 300
> 
> 
> 
> #-------------------------------------------------------------------------------
> # Estimate P(C>t|W) via KM
> #-------------------------------------------------------------------------------
> 
> # view survival time by outcome
> with(dat, tapply(ftime, ftype, summary))
$`0`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   1.00   80.25  148.50  149.43  218.75  286.00 

$`1`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   6.00   28.25   88.00  101.47  161.00  271.00 

> 
> # define CV function for KM
> cv_km <- function(fold) {
+   
+   train_data <- training(dat)
+   valid_data <- validation(dat)
+   
+   #train_data <- dat %>% sample_n(nrow(.)*.9)
+   #valid_data <- dat %>% sample_frac(0.1)
+   #data <- dat
+   
+   # fit KM
+   mod <- survfit(Surv(ftime, ftype==0) ~ 0, data = train_data)
+   
+   # get survival at timepoints for validation
+   km_summary <- summary(mod, time = unique(valid_data$ftime))
+   
+   ## correct estimates to be P(C >= t | A, W)
+   #km_fix <- c(1, km_summary$surv)
+   km_fix_df <- data.frame(km_fix_probs = c(1, km_summary$surv), 
+                           km_fix_times = c(0, km_summary$time))
+   
+   # extract G_t for validation data
+   G_t <- rep(NA, nrow(valid_data))
+   for (this_time in km_fix_df$km_fix_times[-1]) { 
+     n0 <- sum(valid_data$ftime == this_time)
+     G_t[valid_data$ftime == this_time] <- 
+       rep(km_fix_df$km_fix_probs[km_fix_df$km_fix_times == this_time], n0)
+   }
+   #out <- G_t
+   return(list(G_t = G_t))
+ }
> 
> # 10-fold CV for KM predictions
> dat_folds <- make_folds(dat)
> results <- cross_validate(cv_fun = cv_km, 
+                           folds = dat_folds,
+                           use_future = FALSE, .combine = FALSE, 
+                           .combine_control = list())
> 
> # add G_t to dataframe indexing by the folds
> dat$G_t <- NA
> for (i in 1:length(results$G_t)) {
+   dat$G_t[dat_folds[[i]]$validation_set] <- results$G_t[[i]]
+ }
> 
> # replace NAs
> dat <- dat %>% mutate(G_t = replace(G_t, is.na(G_t), min(G_t, na.rm = T)))
> dat %>% arrange(G_t) %>% select(ftime, ftype, G_t) %>% head
  ftime ftype         G_t
1   285     0 0.005295394
2   286     0 0.005295394
3   284     0 0.009963236
4   283     0 0.010590788
5   281     0 0.019203620
6   282     0 0.021261235
> 
> 
> # add in weight and create failure indicator
> dim(dat)
[1]   300 29384
> dat <- dat %>%
+   mutate(
+     ipcw_ftype = ifelse(ftype == 1, 
+                         as.numeric(ftype == 1) / G_t,
+                         0),
+     # create failure time indicator
+     y = as.numeric(ftime > 120)
+   )
> table(dat$y)

  0   1 
128 172 
> with(dat, tapply(ipcw_ftype, status, summary))
$`0`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
      0       0       0       0       0       0 

$`1`
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.011   1.063   1.334   2.137   1.985  16.023 

> with(dat, table(y, status))
   status
y     0   1
  0 106  22
  1 156  16
> 
> #-------------------------------------------------------------------------------
> # sl3
> #-------------------------------------------------------------------------------
> 
> # First task is to perform variable selection for ------------------------------
> # gene expression values
> 
> #options(sl3.verbose = TRUE)
> # set sl3 task
> genes <- grep("ILMN", colnames(dat), value = T)
> length(genes)
[1] 29377
> head(genes)
[1] "ILMN_1343291" "ILMN_1651209" "ILMN_1651228" "ILMN_1651229" "ILMN_1651235"
[6] "ILMN_1651236"
> dat_task <- make_sl3_Task(
+   data = dat,
+   #covariates = c("cancer_stage", "largest_diameter"),
+   covariates = c("cancer_stage", "largest_diameter", genes),
+   outcome = "y",
+   weights = "ipcw_ftype",
+   folds = dat_folds # same folds as used for P(C>t)
+ )
> 
> 
> # set learners --------
> 
> # define xgboost learner
> grid_params <- list(max_depth = c(4, 6, 8),
+                     eta = c(0.001, 0.01, 0.1, 0.2, 0.3),
+                     nrounds = c(20, 50))
> grid <- expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
> params_default <- list(nthread = getOption("sl.cores.learners", 1))
> xgb_learners <- apply(grid, MARGIN = 1, function(params_tune) {
+   do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))})
>   
> # caret learner
> #lrnr_caret_xgboost <- make_learner(Lrnr_caret, algorithm = "xgboost", 
> #                                   tuneLength = 5)
> 
> # other learners
> lrnr_glm <- make_learner(Lrnr_glm)
> lrnr_mean <- make_learner(Lrnr_mean)
> lrnr_lasso <- make_learner(Lrnr_glmnet) # alpha default is 1
> lrnr_ridge <- make_learner(Lrnr_glmnet, alpha = 0)
> lrnr_elasticnet <- make_learner(Lrnr_glmnet, alpha = .5)
> lrnr_gam <- make_learner(Lrnr_gam)
> #lrnr_polspline <- make_learner(Lrnr_polspline)
> 
> # set stack
> stack <- make_learner(
+   Stack, 
+   lrnr_glm, lrnr_mean, lrnr_ridge, lrnr_lasso, lrnr_elasticnet,
+   #lrnr_gam, lrnr_polspline,
+   xgb_learners[[1]], xgb_learners[[2]], xgb_learners[[3]], xgb_learners[[4]], xgb_learners[[5]]
+   ,
+   xgb_learners[[6]], xgb_learners[[7]], xgb_learners[[8]], xgb_learners[[9]], xgb_learners[[10]],
+   xgb_learners[[11]], xgb_learners[[12]], xgb_learners[[13]], xgb_learners[[14]], xgb_learners[[15]],
+   xgb_learners[[16]], xgb_learners[[17]], xgb_learners[[18]], xgb_learners[[19]], xgb_learners[[20]],
+   xgb_learners[[21]], xgb_learners[[22]], xgb_learners[[23]], xgb_learners[[24]], xgb_learners[[25]], 
+   xgb_learners[[26]], xgb_learners[[27]], xgb_learners[[28]], xgb_learners[[29]], xgb_learners[[30]]
+   )
> 
> 
> # simple learner
> stack <- make_learner(
+   Stack, 
+   lrnr_glm, lrnr_mean, lrnr_ridge, lrnr_lasso, lrnr_elasticnet
+ )
> 
> # screeners --------
> screen_rf <- make_learner(Lrnr_screener_randomForest, #nVar = 20, ntree = 20)
+                           nVar = ncol(dat)-1, 
+                           #nVar = 20,
+                           ntree = 200)
> screen_lasso <- make_learner(Lrnr_glmnet)
> 
> # add screener to pipline
> screener_pipeline <- make_learner(Pipeline, 
+                                   screen_lasso,
+                                   screen_rf, 
+                                   stack)
> 
> # complete stack
> fancy_stack <- make_learner(Stack, screener_pipeline, stack)
> 
> # set sl
> sl <- Lrnr_sl$new(
+   learners = fancy_stack,
+   loss = loss_loglik_binomial
+ )
> 
> #availableCores() 
> #options(future.fork.enable = FALSE) ## automatically set in RStudio
> #supportsMulticore()
> #plan(multiprocess)
> #f <- future(1)
> #class(f)
> #f <- future(Sys.getpid())
> #value(f)
> #Sys.getpid()
> #plan(multiprocess, workers = 8)
> options(sl3.verbose = TRUE)
> sl_fit <- sl$train(dat_task)
